---
aliases: [optimization problems]
tags: [zettel]
projects: [Advanced-AI]
title: Optimization Problems
linter-yaml-title-alias: Optimization Problems
date created: Wednesday, February 8th 2023, 9:03:16 am
date modified: Wednesday, February 8th 2023, 9:03:16 am
---

# Optimization Problems
assuming minimization from now on. 

**Def:** minimize $f(x)$ subject to $f_i(x)\leq b_i \, , \, 1, \cdots , m$
$x = (x_0, \cdots , x_n)$ are optimization/decision variables
$f_0 : \mathbb{R}^n \rightarrow \mathbb{R}$ is the objective function
$f_i : \mathbb{R}^n \rightarrow \mathbb{R}$, $i = 1, \cdots, m$ are constraint functions
optimally: find $\bf{x}^\ast$ that has the smallest value for $f_0$ among all $\bf{x}$ satisfying the constraints

## Least Squares
let $f(\bf{x}, \bf{\beta}) = \beta_0 + \sum_{i=0}^n \beta_i x_i$. we want o find coefficients $\bf{\beta}$ to minimize residuals (error) $\min|\bf{y} - \bf{x}\bf{\beta}|_2^2$ 

can be solved analytically: $\beta^\ast = (\bf{x}^T\bf{x})^{-1}\bf{x}^T\bf{y}$ 

## Linear Programming
$\min \mathbb{c}^T \bf{x}$ subject to $\bf{a}_i^T \bf{x} \leq \bf{b}_i, \, i=1, \cdots, m$ 
not NP-complete

simplex: follow the vertices of the convex hull. Break down if general form is violated.

## Separating Hyperplanes Theorem
if $\mathbb{C}$ and $\mathbb{D}$ are non-empty, disjoint (removes noise), convex sets $\longrightarrow$ $\exists \, \vec{a} \neq \bf{0}$ and $b$ s.t. $\vec{a}^T \bf{x} \leq \bf{b}$ for $\bf{x} \in \mathbb{C}$, and $\vec{a}^T\bf{x} \geq \bf{b}$ for $\bf{x}\in \mathbb{D}$. The hyperplane $\{\bf{x} | \vec{a}^T \bf{x}= \bf{b}\}$ separates $\mathbb{C}$ and $\mathbb{D}$ 

## General Descent Methods
- line search: Newtonâ€™s method
- Gradient decent

## Constraints


